{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scipy.sparse as sps\n",
    "import scipy.linalg as sl\n",
    "from sksparse.cholmod import cholesky\n",
    "\n",
    "import enterprise\n",
    "from enterprise.pulsar import Pulsar\n",
    "import enterprise.signals.parameter as parameter\n",
    "import enterprise.constants as const\n",
    "from enterprise.signals import signal_base\n",
    "from enterprise.signals import selections\n",
    "from enterprise.signals.selections import Selection\n",
    "from enterprise.signals import white_signals\n",
    "from enterprise.signals import utils\n",
    "from enterprise.signals import gp_signals\n",
    "from enterprise.signals.utils import KernelMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data and noise locations\n",
    "datadir = '/home/marvin/NANOGrav/perm-data/9yr/'\n",
    "noisedir = '/home/marvin/NANOGrav/perm-data/noise/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parfiles = sorted(glob.glob(datadir+'par/'+'*.par'))\n",
    "timfiles = sorted(glob.glob(datadir+'tim/'+'*.tim'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psr = Pulsar(parfiles[1], timfiles[1], ephem='DE436')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now, let's just add EFAC\n",
    "efac = parameter.Constant()\n",
    "equad = parameter.Constant()\n",
    "ecorr = parameter.Constant()\n",
    "\n",
    "selection = selections.Selection(selections.by_backend)\n",
    "\n",
    "ef = white_signals.MeasurementNoise(efac=efac, selection=selection)\n",
    "eq = white_signals.EquadNoise(log10_equad=equad, selection=selection)\n",
    "ec = gp_signals.EcorrBasisModel(log10_ecorr=ecorr, selection=selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll try to add red noise\n",
    "log10_A = parameter.Constant()\n",
    "gamma = parameter.Constant()\n",
    "\n",
    "# define powerlaw PSD and red noise signal\n",
    "pl = utils.powerlaw(log10_A=log10_A, gamma=gamma)\n",
    "rn = gp_signals.FourierBasisGP(pl, components=30, name='rn')\n",
    "\n",
    "# linearized timing model\n",
    "tm = gp_signals.TimingModel(use_svd=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the full signal, which is just the EFAC here\n",
    "s = ef + eq + ec + rn + tm\n",
    "s2 = ef + eq + ec + rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize PTA\n",
    "model = [s(psr)]\n",
    "pta = signal_base.PTA(model)\n",
    "\n",
    "model2 = [s2(psr)]\n",
    "pta2 = signal_base.PTA(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: enterprise.signals.signal_base: Setting B1937+21_L-wide_ASP_efac to 2.16858\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_L-wide_PUPPI_efac to 2.50409\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_Rcvr1_2_GASP_efac to 1.19848\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_Rcvr1_2_GUPPI_efac to 1.52287\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_Rcvr_800_GASP_efac to 2.36834\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_Rcvr_800_GUPPI_efac to 4.54677\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_S-wide_ASP_efac to 1.42143\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_S-wide_PUPPI_efac to 4.46457\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_L-wide_ASP_log10_equad to -6.78159\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_L-wide_PUPPI_log10_equad to -7.19268\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_Rcvr1_2_GASP_log10_equad to -7.09868\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_Rcvr1_2_GUPPI_log10_equad to -7.08918\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_Rcvr_800_GASP_log10_equad to -6.67489\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_Rcvr_800_GUPPI_log10_equad to -6.63324\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_S-wide_ASP_log10_equad to -6.63809\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_S-wide_PUPPI_log10_equad to -7.13706\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_basis_ecorr_L-wide_ASP_log10_ecorr to -6.74268\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_basis_ecorr_L-wide_PUPPI_log10_ecorr to -6.90359\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_basis_ecorr_Rcvr1_2_GASP_log10_ecorr to -7.01081\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_basis_ecorr_Rcvr1_2_GUPPI_log10_ecorr to -6.65849\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_basis_ecorr_Rcvr_800_GASP_log10_ecorr to -8.44582\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_basis_ecorr_Rcvr_800_GUPPI_log10_ecorr to -6.461\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_basis_ecorr_S-wide_ASP_log10_ecorr to -6.60026\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_basis_ecorr_S-wide_PUPPI_log10_ecorr to -6.39305\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_rn_log10_A to -13.2393\n",
      "INFO: enterprise.signals.signal_base: Setting B1937+21_rn_gamma to 2.46521\n"
     ]
    }
   ],
   "source": [
    "noisefile = noisedir + 'noisedict.json'\n",
    "setpars = {}\n",
    "with open(noisefile, 'r') as fin:\n",
    "    setpars.update(json.load(fin))\n",
    "\n",
    "# fix the white noise parameters to the values in the noisefiles\n",
    "pta.set_default_params(setpars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {k:v for (k,v) in setpars.items() if k.startswith(psr.name)}\n",
    "def get_params(noisefile, psr):\n",
    "    pars = {}\n",
    "    with open(noisefile, 'r') as f:\n",
    "        pars.update(json.load(f))\n",
    "    \n",
    "    params = {k:v for (k,v) in pars.items() if k.startswith(psr.name) and not k.endswith('ecorr')}\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_N(sc, psr):\n",
    "    # Function to construct white noise matrix `N`\n",
    "    # For now it only accomadates single pulsar PTAs\n",
    "    \n",
    "    # W matrix is a diagonal matrix of TOA uncertainties squared\n",
    "    W = np.diag(psr.toaerrs) ** 2\n",
    "\n",
    "    # Separate out different types of white noise\n",
    "    ef_noise = sc._signals[0]\n",
    "    eq_noise = sc._signals[1]\n",
    "\n",
    "    # Let's divide up into our different observing systems (our k's)\n",
    "    # First we need to generate a 'mask' dictionary, aka matching receivers\n",
    "    # to the TOAs they measured\n",
    "    sel = selection(psr)\n",
    "    masks = sel.masks\n",
    "\n",
    "    ef_vals = [l.value**2 for l in list(ef_noise._params.values())]\n",
    "    ef_dict = dict(zip(ef_noise._keys, ef_vals))\n",
    "\n",
    "    eq_vals = [10**(2*l.value) for l in list(eq_noise._params.values())]\n",
    "    eq_dict = dict(zip(eq_noise._keys, eq_vals))\n",
    "\n",
    "    # Now we construct the N_k dictionary, one N matrix per backend+receiver combo\n",
    "    # Then sum them together to get the final N\n",
    "    N_k = {}\n",
    "    for key, mask in masks.items():\n",
    "        N_k[key] = (ef_dict[key] * W + eq_dict[key]*np.identity(len(psr.toas))) * mask\n",
    "\n",
    "    N = sum(N_k.values())\n",
    "    \n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_basis(psr):\n",
    "    Ti = psr.toas.max() - psr.toas.min()\n",
    "    fmin = 1/Ti\n",
    "    fmax = 30/Ti\n",
    "    f = np.linspace(fmin, fmax, 30)\n",
    "    ranphase = np.zeros(30)\n",
    "    \n",
    "    Ffreqs = np.repeat(f, 2)\n",
    "    N = len(psr.toas)\n",
    "    F = np.zeros((N, 2*30))\n",
    "    \n",
    "    F[:, ::2] = np.sin(2 * np.pi * psr.toas[:, None] * f[None, :] + ranphase[None, :])\n",
    "    F[:, 1::2] = np.cos(2 * np.pi * psr.toas[:, None] * f[None, :] + ranphase[None, :])\n",
    "    \n",
    "    basis = F, Ffreqs\n",
    "    return basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_TNr(T, Nvec, r):\n",
    "    mult = np.array(r/Nvec)\n",
    "    TNr = np.dot(T.T, mult)\n",
    "    return TNr\n",
    "\n",
    "def get_TNT(T, Nvec):\n",
    "    TNT = np.dot(T.T, np.array(T/Nvec[:, None]))\n",
    "    return TNT\n",
    "\n",
    "def get_rT_Ninv_r(r, N):\n",
    "    rT = np.transpose(r)\n",
    "    Ninv = np.linalg.inv(N)\n",
    "    \n",
    "    rT_Ninv_r = np.dot(rT, np.dot(Ninv, r))\n",
    "    return rT_Ninv_r\n",
    "\n",
    "def get_phiinv(phi):\n",
    "    phiinv = 1.0 / phi\n",
    "    logdet_phi = np.sum(np.log(phi))\n",
    "    \n",
    "    return phiinv, logdet_phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_likelihood(pta, psr, params):\n",
    "    # Currently this function only works for a single pulsar\n",
    "    # it will be updated in the future to adapt to multiple-pulsar PTAs\n",
    "    ln_likelihood = 0\n",
    "    \n",
    "    sc = pta.pulsarmodels[0]\n",
    "    priordict = {psr.name + '_basis_ecorr': ecorr_prior,\n",
    "                 psr.name + '_rn': rn_prior,\n",
    "                 psr.name + '_linear_timing_model': timing_prior}\n",
    "    \n",
    "    r = psr.residuals\n",
    "    \n",
    "    N = construct_N(sc, psr)\n",
    "    Nvec = np.diag(N)\n",
    "    logdet_N = np.sum(np.log(Nvec))\n",
    "    \n",
    "    T = construct_T(sc, params)\n",
    "    \n",
    "    phi = construct_phi(sc, params, priordict)\n",
    "    phiinv, logdet_phi = get_phiinv(phi)\n",
    "\n",
    "    TNr = get_TNr(T, Nvec, r)\n",
    "    TNT = get_TNT(T, Nvec)\n",
    "    rT_Ninv_r = get_rT_Ninv_r(r, N)\n",
    "    \n",
    "    Sigma = TNT + (np.diag(phiinv) if phiinv.ndim == 1 else phiinv)\n",
    "    cf = sl.cho_factor(Sigma)\n",
    "    expval = sl.cho_solve(cf, TNr)\n",
    "    logdet_sigma = np.sum(2 * np.log(np.diag(cf[0])))\n",
    "    \n",
    "    ln_likelihood += -0.5 * (rT_Ninv_r + logdet_N)\n",
    "    ln_likelihood += 0.5 * (np.dot(TNr, expval) - logdet_sigma - logdet_phi)\n",
    "    return ln_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecorr_prior(signal, params=params, psr=psr):\n",
    "    return [10**(2*l.value) for l in list(signal._params.values())]\n",
    "\n",
    "def rn_prior(psr, params, signal=None, components=2):\n",
    "    _, f = fourier_basis(psr)\n",
    "    log10_A = params[psr.name+'_rn_log10_A']\n",
    "    gamma = params[psr.name+'_rn_gamma']\n",
    "    \n",
    "    df = np.diff(np.concatenate((np.array([0]), f[::components])))\n",
    "    return (\n",
    "        (10 ** log10_A) ** 2 / 12.0 / np.pi ** 2 * const.fyr ** (gamma - 3) * f ** (-gamma) * np.repeat(df, components)\n",
    "    )\n",
    "\n",
    "def timing_prior(psr, params=None, signal=None):\n",
    "    weights = np.ones_like(psr.Mmat.shape[1])\n",
    "    return weights * 1e40\n",
    "\n",
    "def construct_basis(signal, params):\n",
    "    bases, labels = {}, {}\n",
    "    for key, mask in zip(signal._keys, signal._masks):\n",
    "        bases[key], labels[key] = signal._bases[key](params=params, mask=mask)\n",
    "\n",
    "    nc = sum(F.shape[1] for F in bases.values())\n",
    "    basis = np.zeros((len(signal._masks[0]), nc))\n",
    "    slices = {}\n",
    "    nctot = 0\n",
    "\n",
    "    for key, mask in zip(signal._keys, signal._masks):\n",
    "        Fmat = bases[key]\n",
    "        nn = Fmat.shape[1]\n",
    "        basis[mask, nctot : nn + nctot] = Fmat\n",
    "        slices.update({key: slice(nctot, nn+nctot)})\n",
    "        nctot += nn\n",
    "    \n",
    "    return basis, slices\n",
    "\n",
    "def get_phi(signal, params, prior):\n",
    "    basis, slices = construct_basis(signal, params)\n",
    "    \n",
    "    nc = basis.shape[1]\n",
    "    phi = KernelMatrix(nc)\n",
    "    \n",
    "    priorvals = prior(signal=signal, params=params, psr=psr)\n",
    "    if len(signal._keys) > 1:\n",
    "        priordict = dict(zip(signal._keys, priorvals))\n",
    "    elif len(signal._keys) == 1:\n",
    "        priordict = {signal._keys[0]: priorvals}\n",
    "    \n",
    "    for key, slc, in slices.items():\n",
    "        ndim = slc.stop - slc.start\n",
    "        phislc = priordict[key] * np.ones(ndim)\n",
    "        phi = phi.set(phislc, slc)\n",
    "    \n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_T(sc, params):\n",
    "    idxlst = list(sc._idx.values())\n",
    "    ncol = idxlst[-1][-1] + 1\n",
    "    nrow = len(sc._residuals)\n",
    "    T = np.zeros((nrow, ncol))\n",
    "    for signal in sc._signals:\n",
    "        if signal in sc._idx:\n",
    "            basis, _ = construct_basis(signal, params)\n",
    "            T[:, sc._idx[signal]] = basis\n",
    "    return T\n",
    "\n",
    "def construct_phi(sc, params, priors):\n",
    "    idxlst = list(sc._idx.values())\n",
    "    ncol = int(idxlst[-1][-1] + 1)\n",
    "    phi = KernelMatrix(ncol)\n",
    "    for signal in sc._signals:\n",
    "        if signal in sc._idx:\n",
    "            phislc = get_phi(signal, params, priors[signal.name])\n",
    "            phi = phi.add(phislc, sc._idx[signal])\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137508.07755601435\n",
      "137508.07755601435\n"
     ]
    }
   ],
   "source": [
    "loglike = custom_likelihood(pta, psr, params)\n",
    "print(pta.get_lnlikelihood(params))\n",
    "print(loglike)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
